---
title: "Importance weighted moment matching for fast Bootstrapping"
author: "Topi Paananen"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction

In this case study, we will study generic methods to detect misspecification
of Bayesian models. We will use the probabilistic programming framework Stan
to fit our models. As a tool for detecting misspecification, we will look at
the distribution of posterior means when Bootstrapping the data.
For a correctly specified model, as the number of observations becomes large
enough, the posterior distribution of the model and the distribution of
Bootstrapped posterior means should match.

In order to compare the model posterior to the distribution of the Bootstrap means,
we need a large number of Bootstrap repetitions.
Because refitting the model to a large number of resampled data sets is expensive,
we will only fit our model to the original data and use importance sampling
to speed up the Bootstrap procedure. This saves computation time but can give rise to errors
when there is a large mismatch between the original posterior and the Bootstrap posteriors.
To solve this issue, we use importance weighted moment matching (IWMM) which
is a generic adaptive importance sampling algorithm (Paananen et al. 2020).

## Setup

We will load __rstan__ for fitting our models, and the
[_iwmm package_](https://github.com/topipa/iwmm) for
the importance weighted moment matching.
We also load the __loo__ package for some helper functions, and the __parallel__
package for parallellisation.


```{r load, message=FALSE}
library("rstan")
library("loo")
library("parallel")
library("iwmm")
seed <- 48571056
set.seed(seed)
CORES <- 6
```

## Example 1: Correct model - Gaussian data and Gaussian model

### Coding the Stan model

```{r stancode}
stancode <- "data {
  int<lower=0> N;
  vector[N] x;
}
parameters {
  real mu;
  real logsigma;
}
transformed parameters {
  real<lower=0> sigma;
  sigma = exp(logsigma);
}
model {
  x ~ normal(mu,sigma);
}
generated quantities {
  vector[N] log_lik;
  vector[N] xpred;
  for (n in 1:N)
  {
    log_lik[n] = normal_lpdf(x[n] | mu, sigma);
    xpred[n] = normal_rng(mu, sigma);
  }
}"
```

For importance sampling and Bootstrap, we need the log-likelihood for each observation.
Thus, following the usual approach recommended in
[_Writing Stan programs for use with the loo package_](http://mc-stan.org/loo/articles/loo2-with-rstan.html),
we compute the log-likelihood for each observation in the
`generated quantities` block of the Stan program.

### Fitting the model with RStan

First we simulate Gaussian data and fit the correctly specified model with
Stan using the rstan package:

```{r modelfit1, message=FALSE, echo=T, results='hide'}
stanmodel <- stan_model(model_code = stancode)

# generate  data
n = as.integer(1000)
x = rnorm(n = n)

standata = list(N = n, x = x)
stanfit <- sampling(stanmodel, data = standata, refresh = 0)

# extract posterior and log-likelihood draws
post <- as.data.frame(stanfit)[,1:2]
S <- nrow(post)
ll <- loo::extract_log_lik(stanfit)
```

### Compute Bootstrap means using importance sampling

Now let us resample our simulated data in a Bootstrap fashion, and use importance
sampling to compute the Bootstrap posterior means. To diagnose the reliability of importance
sampling, we compute the Pareto k diagnostics (See Vehtari et al. (2017) for details).

```{r naiveIS, warning=FALSE}
# compute Bootstrap weights
bs_S <- 500
obs_ws <- apply(matrix(seq(bs_S)), 1, function(x) {c(rmultinom(1,n,prob = rep(1,n)/n))})

bs_postmeans_is <- matrix(0,bs_S,2)
ks <- rep(0,bs_S)

iw_list <- parallel::mclapply(X = seq(bs_S), mc.cores = CORES, FUN = function(i) {
  obs_w_matrix <- matrix(obs_ws[,i],S,n, byrow = TRUE)
  lw <- rowSums((obs_w_matrix - 1) * ll)
  lw <- lw - matrixStats::logSumExp(lw)
  psis <- psis(lw)
  c(colSums(exp(lw) * post),psis$diagnostics$pareto_k)
})

iw_list <- array(as.numeric(unlist(iw_list)),c(3,bs_S))
ks <- iw_list[3,]
```

Let us plot the Pareto k diagnostics to see if the importance sampling accuracy can be trusted:

```{r plotk1}
plot(sort(ks), pch = 20)
```

We notice that there are several Pareto k values that are large (> 0.7), indicating that the Bootstrap
means can be biased.

### Compute Bootstrap means using IWMM

In order to get accurate results with importance sampling, we will use
importance weighted moment matching (IWMM).
This will require more computations compared to simple
importance sampling, but is still significantly cheaper than
refitting the model for each resampled data set.

We will use the `moment_match` function from the __iwmm__ package.
There is a separate version of the function for `stanfit` objects.
The function requires two arguments: 1) A `stanfit` object, and 2)
a function `log_ratio_fun` that computes the ratio of the target density
(the Bootstrap posterior) and the proposal density (the standard posterior).
For `log_ratio_fun`, we give a third argument that represents the Bootstrap
weights of each observation, which in this case represent the number of
times each observation is included in the Bootstrap sample.

The `moment_match` function checks the Pareto k diagnostic of each Bootstrap repetition,
and if it is above a determined threshold, it will adapt the proposal distribution
to improve importance sampling accuracy. Here we use the default value
`k_threshold = 0.5`.


```{r helper functions, warning = FALSE}
log_lik_stanfit <- function(stanfit, upars, parameter_name = "log_lik",
                                      ...) {
    ll <- loo::extract_log_lik(stanfit, parameter_name, merge_chains = TRUE)
    S <- nrow(upars)
    n <- ncol(ll)
    out <- matrix(0,S,n)
    for (s in seq_len(S)) {
      out[s,] <- rstan::constrain_pars(stanfit, upars = upars[s, ])[[parameter_name]]
    }
    out
  }

ratio_density <- function(draws, stanfit, obs_weights, ...) {
    log_lik <- log_lik_stanfit(stanfit, draws)
    colSums((obs_weights - 1) * t(log_lik))
}
```

```{r iwmm1, warning = FALSE}
bs_postmeans_is_mm <- matrix(0,bs_S,2)
ks_mm <- rep(0,bs_S)


iw_list <- parallel::mclapply(X = seq(bs_S), mc.cores = CORES, FUN = function(i) {
  iw <- moment_match(stanfit, log_ratio_fun = ratio_density, obs_weights = obs_ws[,i])
  c(matrixStats::colWeightedMeans(iw$draws, exp(iw$log_weights)),iw$pareto_k)
})
iw_list <- array(as.numeric(unlist(iw_list)),c(3,bs_S))

bs_postmeans_is_mm <- data.frame("mu" = iw_list[1,], "logsigma" = iw_list[2,])
ks_mm <- iw_list[3,]
```

Let us check the Pareto k diagnostic values :

```{r plotk2}
plot(sort(ks),
     pch = 20,
     ylim = c(min(ks_mm),max(ks)),
     col = 'black',
     xlab = "Bootstrap index",
     ylab = "Pareto k",
     main = "Pareto k diagnostics")
points(ks_mm[order(ks)], col = 'green',pch = 20)
points(c(-1,1000),c(0.5,0.5), type = 'l')
legend("topleft",legend = c("IS","IWMM"), col = c('black','green'), pch = 20)
```

Now all Pareto k values are below 0.5, so the Bootstrap means should be accurate.
Let us plot both the original posterior samples and the Bootstrap posterior means:

```{r plotdraws1}
hist(post$mu,
     col=rgb(0,0,1,1/4),
     freq = FALSE,
     ylim = c(0,25),
     xlab = "mu",
     ylab = "count",
     main = "Posterior of mu")
hist(bs_postmeans_is_mm$mu, col=rgb(1,0,0,1/4), add = T, freq = FALSE)
legend("topright",legend = c("model posterior","Bootstrap posterior means"),
       fill = c(rgb(0,0,1,1/4),rgb(1,0,0,1/4)))

```

```{r plotdraws2}
hist(post$logsigma,
     col=rgb(0,0,1,1/4),
     freq = FALSE,
     ylim = c(0,50),
     xlab = "log(sigma)",
     ylab = "count",
     main = "Posterior of log(sigma)",
     breaks = seq(-0.1,0.15, length.out = 30))
hist(bs_postmeans_is_mm$logsigma, col=rgb(1,0,0,1/4), add = T, freq = FALSE,
     breaks = seq(-0.1,0.15, length.out = 30))
legend("topright",legend = c("model posterior","Bootstrap posterior means"),
       fill = c(rgb(0,0,1,1/4),rgb(1,0,0,1/4)))

```

As we expect from a correctly specified model, the distribution of the Bootstrap posterior means
matches the posterior distribution of the original data.
Let us next see what happens if the model is clearly misspecified.

## Example 2: Misspecified model - $t$-distributed data and Gaussian model

```{r modelfit2, message=FALSE}
stanmodel <- stan_model(model_code = stancode)

# generate  data
n = as.integer(1000)
x = rt(n = n, df = 3)

standata = list(N = n, x = x)
stanfit <- sampling(stanmodel, data = standata, refresh = 0)

# extract posterior and log-likelihood draws
post <- as.data.frame(stanfit)[,1:2]
S <- nrow(post)
ll <- loo::extract_log_lik(stanfit)
```


### Compute Bootstrap means using IWMM

```{r iwmm2, warning = FALSE}

bs_postmeans_is_mm <- matrix(0,bs_S,2)
ks_mm <- rep(0,bs_S)

iw_list <- parallel::mclapply(X = seq(bs_S), mc.cores = CORES, FUN = function(i) {
  iw <- moment_match(stanfit, log_ratio_fun = ratio_density, obs_weights = obs_ws[,i])
  c(matrixStats::colWeightedMeans(iw$draws, exp(iw$log_weights)),iw$pareto_k)
})
iw_list <- array(as.numeric(unlist(iw_list)),c(3,bs_S))

bs_postmeans_is_mm <- data.frame("mu" = iw_list[1,], "logsigma" = iw_list[2,])
ks_mm <- iw_list[3,]
```


Let us check the Pareto k diagnostic values :

```{r plotk3}
plot(sort(ks_mm),
     pch = 20,
     ylim = c(min(ks_mm),max(ks_mm)),
     col = 'green',
     xlab = "Bootstrap index",
     ylab = "Pareto k",
     main = "Pareto k diagnostics")
# points(ks_mm[order(ks)], col = 'green',pch = 20)
points(c(-1,1000),c(0.5,0.5), type = 'l')
legend("topleft",legend = c("IS","IWMM"), col = c('black','green'), pch = 20)

```

All diagnostic values are below 0.5, so the Bootstrap means should be accurate.
Let us plot both the original posterior samples and the Bootstrap posterior means:

```{r plotdraws3}
hist(post$mu,
     col=rgb(0,0,1,1/4),
     freq = FALSE,
     ylim = c(0,25),
     xlab = "mu",
     ylab = "count",
     main = "Posterior of mu")
hist(bs_postmeans_is_mm$mu, col=rgb(1,0,0,1/4), add = T, freq = FALSE)
legend("topright",legend = c("model posterior","Bootstrap posterior means"),
       fill = c(rgb(0,0,1,1/4),rgb(1,0,0,1/4)))
```

```{r plotdraws4}
hist(post$logsigma,
     col=rgb(0,0,1,1/4),
     freq = FALSE,
     ylim = c(0,50),
     xlab = "log(sigma)",
     ylab = "count",
     main = "Posterior of log(sigma)",
     breaks = seq(0.2,1.0, length.out = 30))
hist(bs_postmeans_is_mm$logsigma, col=rgb(1,0,0,1/4), add = T, freq = FALSE,
     breaks = seq(0.2,1.0, length.out = 30))
legend("topright",legend = c("model posterior","Bootstrap posterior means"),
       fill = c(rgb(0,0,1,1/4),rgb(1,0,0,1/4)))

```


Now we see that there is a clear difference between the two distributions.
Because the data is from a $t$-distribution, but we are modelling
it as Gaussian, the model underestimates the uncertainty about the standard deviation
parameter `logsigma`.

We can confirm a similar misspecification using posterior predictive checks.
Below we plot a density plot of the data together with multiple
data sets simulated from the model.

```{r}
xpred <- extract(stanfit)$xpred
bayesplot::ppc_dens_overlay(x, xpred[1:100,])
```


In this example, the Bootstrap and posterior predictive checks are complementary
approaches for detecting model misspecification.
However, the importance weighted moment matching can be used to speed up
Bootstrap for other applications as well. It is also applicable
to many other Monte Carlo sampling and importance sampling tasks.




## References

Paananen, T., Piironen, J., Buerkner, P.-C., Vehtari, A. (2020). Implicitly Adaptive Importance Sampling. [arXiv preprint arXiv:1906.08850](http://arxiv.org/abs/1906.08850).

Stan Development Team (2020) _RStan: the R interface to Stan, Version 2.21.2_   https://mc-stan.org

Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. _Statistics and Computing_. 27(5), 1413--1432. \doi:10.1007/s11222-016-9696-4. Links: [published](http://link.springer.com/article/10.1007\%2Fs11222-016-9696-4) | [arXiv preprint](http://arxiv.org/abs/1507.04544).

